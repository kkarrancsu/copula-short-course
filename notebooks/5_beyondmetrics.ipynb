{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c230487",
   "metadata": {},
   "outputs": [],
   "source": "# Lesson 5: Beyond Traditional Metrics\n# This notebook explores the limitations of traditional correlation metrics\n# and demonstrates why we need more robust measures of dependence.\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nfrom IPython import display\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\n\nimport numpy as np"
  },
  {
   "cell_type": "markdown",
   "id": "5lygt4jp0b8",
   "source": "# Lesson 5: Beyond Traditional Metrics\n\nThis notebook explores the limitations of traditional correlation metrics and demonstrates why we need more robust measures of dependence. We will see how outliers can dramatically affect sample statistics and introduce the bivariate Gaussian distribution as a foundation for understanding joint distributions.\n\n## Learning Objectives\n- Understand the sensitivity of traditional metrics to outliers\n- Review the bivariate Gaussian distribution\n- Recognize the limitations of Pearson correlation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc73f96",
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate how outliers can dramatically shift the mean\n# This motivates the need for robust dependence measures\n\n# Generate normal data with some extreme outliers\nx1 = np.random.normal(size=(50))\noutliers = 10*[80]  # Add 10 extreme outlier values\nx = np.concatenate([x1, outliers])\n\n# Visualize the impact of outliers on the mean\nplt.figure()\nsns.kdeplot(x, label='Data Distribution')\nplt.axvline(np.mean(x1), color='r', label='$\\mu$ without Outlier')\nplt.axvline(np.mean(x), color='k', label='$\\mu$ with Outlier')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title('Impact of Outliers on the Sample Mean')\nplt.legend()"
  },
  {
   "cell_type": "markdown",
   "id": "de5bcd7a",
   "metadata": {},
   "source": "## The Bivariate Gaussian Distribution\n\nThe bivariate Gaussian (normal) distribution is a fundamental model for understanding joint distributions. It is completely characterized by five parameters: two means ($\\mu_x$, $\\mu_y$), two standard deviations ($\\sigma_x$, $\\sigma_y$), and a correlation coefficient ($\\rho$).\n\n### Joint Probability Density Function\n\n$$ f(x,y) = \\frac{1}{2 \\pi \\sigma_x \\sigma_y \\sqrt{1-\\rho^2}} \\text{exp} \\left( -\\frac{1}{2(1-\\rho^2)} \\left[ \\left( \\frac{x-\\mu_x}{\\sigma_x} \\right)^2 - 2 \\rho \\left( \\frac{x-\\mu_x}{\\sigma_x} \\right) \\left( \\frac{y-\\mu_y}{\\sigma_y} \\right) +  \\left( \\frac{y-\\mu_y}{\\sigma_y} \\right)^2 \\right] \\right) $$"
  },
  {
   "cell_type": "markdown",
   "id": "5bb70ae7",
   "metadata": {},
   "source": "### Marginal Distribution\n\nThe marginal distribution is obtained by integrating out one variable from the joint distribution. For the bivariate Gaussian, each marginal is itself a univariate Gaussian:\n\n$$f(x) = \\int_{-\\infty}^{\\infty} f(x,y) \\, dy = \\frac{1}{\\sigma_x \\sqrt{2\\pi}} \\text{exp}\\left[-\\frac{1}{2}\\left(\\frac{x-\\mu_x}{\\sigma_x}\\right)^2\\right] $$\n\nNote that the marginal distribution does not depend on the correlation parameter $\\rho$."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc146ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}